"""
Module de g√©n√©ration automatique de scripts SQL d'import
Contient toutes les fonctions n√©cessaires pour analyser les m√©tadonn√©es
et g√©n√©rer des scripts SQL PostgreSQL optimis√©s.
"""

import streamlit as st
import pandas as pd
import re
import io
import csv
from datetime import datetime
from typing import List, Optional, Tuple
from .db_utils import get_db_connection


def normalize_data_type(raw_type: str) -> str:
    """
    Normalise un type de donn√©es brut vers un type SQL standard.
    
    Args:
        raw_type: Type brut trouv√© dans le dictionnaire des variables
        
    Returns:
        Type SQL standardis√© ou None si non reconnu
    """
    if not raw_type:
        return None
    
    type_clean = str(raw_type).strip().lower()
    
    # Mapping des types courants vers SQL
    type_mappings = {
        # Types texte
        'text': 'TEXT',
        'string': 'VARCHAR(255)',
        'str': 'VARCHAR(255)', 
        'char': 'VARCHAR(255)',
        'character': 'VARCHAR(255)',
        'varchar': 'VARCHAR(255)',
        'texte': 'TEXT',
        'cha√Æne': 'VARCHAR(255)',
        'chaine': 'VARCHAR(255)',
        
        # Types num√©riques entiers
        'int': 'INTEGER',
        'integer': 'INTEGER',
        'entier': 'INTEGER',
        'number': 'INTEGER',
        'numeric': 'INTEGER',
        'num': 'INTEGER',
        'bigint': 'BIGINT',
        'smallint': 'SMALLINT',
        
        # Types num√©riques d√©cimaux
        'float': 'DECIMAL(15,6)',
        'decimal': 'DECIMAL(15,6)',
        'double': 'DECIMAL(15,6)',
        'real': 'DECIMAL(15,6)',
        'd√©cimal': 'DECIMAL(15,6)',
        'flottant': 'DECIMAL(15,6)',
        
        # Types date/temps
        'date': 'DATE',
        'datetime': 'TIMESTAMP',
        'timestamp': 'TIMESTAMP',
        'time': 'TIME',
        # CORRECTION : Retirer 'temps' g√©n√©rique pour √©viter "temps partiel" ‚Üí DATE
        # 'temps': 'TIMESTAMP',  # Trop g√©n√©rique, comment√©
        
        # Types bool√©ens
        'boolean': 'BOOLEAN',
        'bool': 'BOOLEAN',
        'bool√©en': 'BOOLEAN',
        'vrai/faux': 'BOOLEAN',
        'oui/non': 'BOOLEAN',
        
        # Types binaires/blob
        'blob': 'BYTEA',
        'binary': 'BYTEA',
        'binaire': 'BYTEA'
    }
    
    # Recherche directe
    if type_clean in type_mappings:
        return type_mappings[type_clean]
    
    # Recherche avec VARCHAR(n)
    varchar_match = re.match(r'varchar\s*\(\s*(\d+)\s*\)', type_clean)
    if varchar_match:
        size = int(varchar_match.group(1))
        return f'VARCHAR({size})'
    
    # Recherche avec DECIMAL(n,m)
    decimal_match = re.match(r'decimal\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', type_clean)
    if decimal_match:
        precision = int(decimal_match.group(1))
        scale = int(decimal_match.group(2))
        return f'DECIMAL({precision},{scale})'
    
    # Types contenant certains mots-cl√©s (patterns PR√âCIS pour √©viter les faux positifs)
    if any(keyword in type_clean for keyword in ['text', 'texte', 'long']):
        return 'TEXT'
    elif any(keyword in type_clean for keyword in ['int', 'entier', 'number']):
        return 'INTEGER'
    elif any(keyword in type_clean for keyword in ['float', 'decimal', 'double']):
        return 'DECIMAL(15,6)'
    elif any(keyword in type_clean for keyword in ['date', 'datetime', 'timestamp']):
        # CORRECTION : Retirer 'temps' g√©n√©rique qui capture "temps partiel"
        # √ätre plus sp√©cifique pour √©viter les faux positifs
        return 'DATE'
    elif any(keyword in type_clean for keyword in ['bool', 'vrai', 'faux']):
        return 'BOOLEAN'
    
    return None


def detect_column_type(clean_values: list, csv_separator: str = ';') -> str:
    """
    D√©tection universelle et intelligente du type SQL pour une colonne.
    Bas√©e uniquement sur l'analyse des donn√©es avec marges x8.
    NOUVELLE R√àGLE : Protection INSEE anti-ZZZZZZ automatique.
    
    Args:
        clean_values: Liste des valeurs nettoy√©es de la colonne
        csv_separator: S√©parateur CSV utilis√© (';' ou ',')
    
    Returns:
        Type SQL appropri√© avec marges x8 de s√©curit√©
    """
    if not clean_values:
        return 'VARCHAR(255)'
    
    # Analyse de base
    max_len = max(len(str(v)) for v in clean_values)
    
    # NOUVELLE R√àGLE PRIORITAIRE : D√©tection explicite des valeurs de masquage INSEE
    has_insee_masking = False
    insee_masking_patterns = ['ZZZZZZ', 'ZZZZZ', 'ZZZZ', 'ZZZ', 'XX', 'XXX', 'XXXX', 's', 'SECRET']
    
    for val in clean_values:
        val_str = str(val).strip().upper()
        if val_str in insee_masking_patterns:
            has_insee_masking = True
            break
    
    # Si masquage INSEE d√©tect√©, forcer VARCHAR m√™me si les autres valeurs sont num√©riques
    if has_insee_masking:
        if max_len <= 10:
            return 'VARCHAR(50)'    # S√©curit√© pour codes + masquage
        elif max_len <= 25:
            return 'VARCHAR(200)'   
        else:
            return 'TEXT'
    
    # Test num√©rique ultra-strict (seulement si pas de masquage INSEE)
    all_numeric = True
    has_decimals = False
    
    for val in clean_values:
        val_str = str(val).strip()
        
        # Test num√©rique selon le s√©parateur
        if csv_separator == ';':
            # Format fran√ßais : virgule = d√©cimal
            if not re.match(r'^-?\d+(,\d*)?$', val_str.replace(' ', '')):
                all_numeric = False
                break
            if ',' in val_str:
                has_decimals = True
        else:
            # Format anglais : point = d√©cimal
            if not re.match(r'^-?\d+(\.\d*)?$', val_str.replace(' ', '')):
                all_numeric = False
                break
            if '.' in val_str:
                has_decimals = True
    
    # D√©cision finale
    if all_numeric:
        return 'DECIMAL(15,6)' if has_decimals else 'INTEGER'
    else:
        # VARCHAR avec marges x8 pures bas√©es uniquement sur les donn√©es
        if max_len <= 5:
            return 'VARCHAR(40)'    # Marge x8
        elif max_len <= 10:
            return 'VARCHAR(80)'    # Marge x8
        elif max_len <= 25:
            return 'VARCHAR(200)'   # Marge x8
        elif max_len <= 50:
            return 'VARCHAR(400)'   # Marge x8
        elif max_len <= 100:
            return 'VARCHAR(800)'   # Marge x8
        else:
            return 'TEXT'


def detect_type_from_description(description: str) -> str:
    """
    D√©tection universelle du type SQL bas√©e sur l'analyse s√©mantique des descriptions.
    Cette fonction exploite les descriptions pour identifier les codes/identifiants (protection anti-ZZZZZZ).
    
    Args:
        description: Description de la variable (libell√© + description longue)
        
    Returns:
        Type SQL sugg√©r√© ou None si aucune d√©tection claire
    """
    if not description:
        return None
        
    desc_lower = description.lower()
    
    # R√àGLE 1 PRIORITAIRE: Comptages ‚Üí INTEGER (plus sp√©cifique, doit venir AVANT les codes)
    counting_keywords = [
        'nombre de', 'count', 'total', 'effectif', 'population', 
        'nb de', 'quantit√©', 'quantite', 'effectifs'
    ]
    if any(keyword in desc_lower for keyword in counting_keywords):
        return 'INTEGER'
    
    # R√àGLE 2: Taux/Pourcentages/Ratios ‚Üí DECIMAL (avant les codes aussi)
    ratio_keywords = [
        'taux', 'pourcentage', 'ratio', 'rate', 'part de', 'proportion',
        'indice', 'moyenne', 'median', 'percentile'
    ]
    if any(keyword in desc_lower for keyword in ratio_keywords):
        return 'DECIMAL(15,6)'
    
    # R√àGLE 3: Codes/Identifiants ‚Üí VARCHAR (protection universelle anti-ZZZZZZ)
    # Attention : exclure "aide"/"aid√©" qui ne sont pas des codes mais des cat√©gories
    code_keywords = [
        'code', 'codes', 'identifiant', 'identifier', 'num√©ro', 'numero', 
        'r√©f√©rence', 'reference', 'cl√©', 'cle', 'key', 'id', 'siren', 'siret'
    ]
    # V√©rification plus stricte : ne pas confondre "aide" avec "code"
    if any(keyword in desc_lower for keyword in code_keywords):
        # Exclure les faux positifs comme "emplois aid√©s", "aides familiaux"
        false_positives = ['emplois aid√©s', 'aides familiaux', 'emploi aid√©', 'aide familial']
        if not any(fp in desc_lower for fp in false_positives):
            return 'VARCHAR(50)'
    
    # R√àGLE 4: Libell√©s/Noms ‚Üí TEXT ou VARCHAR
    text_keywords = [
        'libell√©', 'libelle', 'nom de', 'intitul√©', 'intitule', 
        'designation', 'd√©signation', 'appellation'
    ]
    if any(keyword in desc_lower for keyword in text_keywords):
        return 'VARCHAR(255)'  # Pour les libell√©s courts/moyens
    
    return None  # Aucune d√©tection s√©mantique claire


def detect_column_type_with_column_name(clean_values: list, csv_separator: str, column_name: str) -> str:
    """
    D√©tection universelle et intelligente du type SQL avec prise en compte du nom de colonne.
    Utilise des patterns PR√âCIS pour √©viter les faux positifs.
    
    Args:
        clean_values: Liste des valeurs nettoy√©es de la colonne
        csv_separator: S√©parateur CSV utilis√© (';' ou ',')
        column_name: Nom de la colonne pour appliquer des r√®gles sp√©cifiques
    
    Returns:
        Type SQL appropri√© avec r√®gles intelligentes bas√©es sur le nom
    """
    col_lower = column_name.lower()
    
    # R√àGLE UNIVERSELLE 1 : D√©tection PR√âCISE des identifiants et codes
    # Utilisation de regex pour des patterns exacts et √©viter les faux positifs
    identifier_patterns = [
        # Codes explicites (patterns exacts ou d√©limit√©s)
        r'^code$', r'^cod$', r'^id$', r'_id$', r'^id_', r'_code$', r'^code_',
        r'^identifier$', r'^identifiant$',
        # Codes g√©ographiques INSEE (patterns pr√©cis uniquement)
        r'^iris$', r'^triris$', r'^codgeo$', r'^geocode$', 
        r'^commune$', r'^com$', r'^dep$', r'^reg$', r'^uu\d*$',
        # Codes d'entreprises (patterns pr√©cis)
        r'^siren$', r'^siret$', r'^nic$', r'^ape$', r'^naf$', r'^tva$',
        # Autres identifiants (patterns d√©limit√©s)
        r'^reference$', r'^ref$', r'^numero$', r'^num$', r'^matricule$', 
        r'^cle$', r'^key$', r'_ref$', r'_key$',
        # Libell√©s g√©ographiques (aussi √† prot√©ger)
        r'^libcom$', r'^libiris$', r'^typ_iris$', r'^modif_iris$', r'^lab_iris$',
    ]
    
    # Si le nom de colonne matche un pattern d'identifiant PR√âCIS ‚Üí VARCHAR(50)
    if any(re.search(pattern, col_lower) for pattern in identifier_patterns):
        return 'VARCHAR(50)'
    
    # R√àGLE UNIVERSELLE 2 : Listes de codes ‚Üí VARCHAR(200) minimum
    if (col_lower.startswith('codes_') or 
        ('code' in col_lower and ('liste' in col_lower or 'multiple' in col_lower))):
        # Analyser les donn√©es pour voir si VARCHAR(200) suffit
        base_type = detect_column_type(clean_values, csv_separator)
        if base_type.startswith('VARCHAR'):
            try:
                detected_size = int(base_type.split('(')[1].split(')')[0])
                # Prendre le maximum entre 200 et la taille d√©tect√©e
                return f'VARCHAR({max(200, detected_size)})'
            except:
                return 'VARCHAR(200)'
        elif base_type == 'TEXT':
            return 'TEXT'
        else:
            return 'VARCHAR(200)'  # S√©curit√© par d√©faut
    
    # Sinon, utiliser la d√©tection normale bas√©e sur les donn√©es
    return detect_column_type(clean_values, csv_separator)


def detect_column_type_intelligent_universal(clean_values: list, csv_separator: str, column_name: str, dict_row: list = None) -> str:
    """
    D√©tection universelle et intelligente selon la hi√©rarchie de priorit√©s d√©finie.
    
    HI√âRARCHIE DES PRIORIT√âS :
    1. Type explicite dans le dictionnaire des variables
    2. Analyse s√©mantique des descriptions (protection anti-ZZZZZZ universelle)
    3. Analyse des donn√©es r√©elles
    4. Patterns de noms de colonnes (fallback uniquement)
    
    Args:
        clean_values: Liste des valeurs nettoy√©es de la colonne
        csv_separator: S√©parateur CSV utilis√©
        column_name: Nom de la colonne
        dict_row: Ligne du dictionnaire des variables [nom, libelle, description, ...]
        
    Returns:
        Type SQL appropri√© selon la hi√©rarchie
    """
    
    # PROTECTION G√âOGRAPHIQUE ABSOLUE : Identifiants g√©ographiques critiques
    # Ces colonnes DOIVENT √™tre VARCHAR m√™me si les donn√©es semblent num√©riques (protection anti-ZZZZZZ)
    geographic_critical_patterns = [
        r'^iris$', r'^triris$', r'^codgeo$', r'^geocode$', 
        r'^commune$', r'^com$', r'^dep$', r'^reg$', r'^uu\d*$',
        r'^libcom$', r'^libiris$', r'^typ_iris$', r'^modif_iris$', r'^lab_iris$'
    ]
    col_lower = column_name.lower()
    if any(re.search(pattern, col_lower) for pattern in geographic_critical_patterns):
        return 'VARCHAR(50)'  # Protection absolue
    
    # PRIORIT√â 1 : Type explicite dans le dictionnaire des variables
    if dict_row and len(dict_row) > 0:
        # Rechercher un type explicite dans les colonnes du dictionnaire
        for field in dict_row[1:]:  # √Ä partir de la 2√®me colonne
            field_str = str(field).strip()
            if field_str:
                explicit_type = normalize_data_type(field_str)
                if explicit_type:
                    return explicit_type
    
    # PRIORIT√â 2 : Analyse s√©mantique des descriptions (protection universelle anti-ZZZZZZ)
    if dict_row and len(dict_row) > 1:
        # Concat√©ner libell√© + description pour l'analyse s√©mantique
        description_complete = ' '.join(str(field) for field in dict_row[1:])
        semantic_type = detect_type_from_description(description_complete)
        if semantic_type:
            return semantic_type
    
    # PRIORIT√â 3 : Analyse des donn√©es r√©elles
    data_based_type = detect_column_type(clean_values, csv_separator)
    
    # PRIORIT√â 4 : Affiner avec patterns de noms seulement si n√©cessaire
    # (uniquement pour les cas ambigus de VARCHAR)
    if data_based_type.startswith('VARCHAR') and len(clean_values) > 0:
        # V√©rifier si les patterns de noms peuvent affiner le type
        name_based_type = detect_column_type_with_column_name(clean_values, csv_separator, column_name)
        
        # Si le pattern de nom sugg√®re un type plus pr√©cis, l'utiliser
        if name_based_type != data_based_type and name_based_type in ['VARCHAR(50)', 'VARCHAR(200)']:
            return name_based_type
    
    return data_based_type


def parse_csv_line(line: str, separator: str) -> list:
    """Parse intelligente d'une ligne CSV avec gestion des guillemets."""
    try:
        reader = csv.reader(io.StringIO(line), delimiter=separator, quotechar='"')
        return next(reader)
    except:
        return line.split(separator)


def generate_sql_from_metadata(table_name: str, debug_mode: bool = False) -> str:
    """
    G√©n√®re le script SQL d'import bas√© sur les m√©tadonn√©es.
    
    Args:
        table_name: Nom de la table pour laquelle g√©n√©rer le script
        debug_mode: Si True, affiche les informations de debug via Streamlit
    
    Returns:
        Script SQL complet ou message d'erreur
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM metadata WHERE nom_table = %s", (table_name,))
        result = cursor.fetchone()
        
        if not result:
            return f"‚ùå Table '{table_name}' non trouv√©e dans les m√©tadonn√©es"
        
        columns = [desc[0] for desc in cursor.description]
        metadata = dict(zip(columns, result))
        
        # Extraction des infos principales
        nom_table = metadata.get('nom_table', 'unknown_table')
        schema = metadata.get('schema', 'public')
        description = metadata.get('description', '')
        producteur = metadata.get('producteur', '')
        
        # R√©cup√©ration de la structure CSV
        contenu_csv = metadata.get('contenu_csv', {})
        if not contenu_csv or 'header' not in contenu_csv:
            return f"‚ùå Structure CSV non disponible pour '{table_name}'"
        
        colonnes = contenu_csv['header']
        separateur = contenu_csv.get('separator', ';')
        donnees_exemple = contenu_csv.get('data', [])
        
        # Affichage de debug optionnel
        if debug_mode:
            st.write(f"üîç DEBUG: Colonnes trouv√©es: {len(colonnes)}")
            st.write(f"üîç DEBUG: Donn√©es d'exemple: {len(donnees_exemple)} lignes")
        
        # G√©n√©ration du SQL
        sql = f"""-- =====================================================================================
-- SCRIPT D'IMPORT POUR LA TABLE {nom_table}
-- =====================================================================================
-- Producteur: {producteur}
-- Schema: {schema}
-- Genere automatiquement le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- 
-- NOUVELLE HI√âRARCHIE DE D√âTECTION UNIVERSELLE ET INTELLIGENTE :
-- 1. Type explicite dans le dictionnaire des variables (si disponible)
-- 2. Analyse s√©mantique des descriptions (protection anti-ZZZZZZ universelle)
-- 3. Analyse des donn√©es r√©elles (avec d√©tection masquage)
-- 4. Patterns de noms de colonnes (fallback pr√©cis uniquement)
-- =====================================================================================

-- 1. Suppression de la table existante (si elle existe)
DROP TABLE IF EXISTS "{schema}"."{nom_table}";

-- 2. Creation de la table
CREATE TABLE "{schema}"."{nom_table}" (
"""
        
        # R√©cup√©ration du dictionnaire des variables s'il existe
        dictionnaire = metadata.get('dictionnaire', {})
        dict_data = dictionnaire.get('data', []) if dictionnaire else []
        
        # Traitement des colonnes avec la nouvelle logique intelligente
        cols = []
        for i, col in enumerate(colonnes):
            col_clean = col.strip()
            
            # R√©cup√©ration des valeurs d'exemple pour cette colonne
            sample_values = [row[i] if len(row) > i else None for row in donnees_exemple]
            clean_values = [str(v).strip() for v in sample_values if v is not None and str(v).strip()]
            
            # Recherche de la ligne correspondante dans le dictionnaire des variables
            dict_row = None
            if dict_data:
                for row in dict_data:
                    if len(row) >= 1 and row[0].strip().lower() == col.lower():
                        dict_row = row
                        break
            
            # NOUVELLE LOGIQUE UNIVERSELLE : Utilisation de la hi√©rarchie de priorit√©s
            sql_type = detect_column_type_intelligent_universal(
                clean_values=clean_values,
                csv_separator=separateur,
                column_name=col_clean,
                dict_row=dict_row
            )
            
            # Debug optionnel
            if debug_mode:
                if dict_row:
                    st.write(f"üîç DEBUG {col_clean} - Dictionnaire: {dict_row}")
                st.write(f"üîç DEBUG {col_clean} - Type d√©tect√©: {sql_type}")
            
            cols.append(f'    "{col_clean}" {sql_type}')
        
        sql += ",\n".join(cols)
        sql += "\n);\n"
        
        # Description
        if description:
            desc_lines = description.replace('\r\n', '\n').replace('\r', '\n').split('\n')
            sql += "\n-- ====================================================================================="
            sql += "\n-- DESCRIPTION DES DONNEES"
            sql += "\n-- ====================================================================================="
            for line in desc_lines:
                sql += f"\n-- {line}"
            sql += "\n-- ====================================================================================="
        
        conn.close()
        return sql
        
    except Exception as e:
        error_msg = f"‚ùå Erreur lors de la g√©n√©ration : {str(e)}"
        if debug_mode:
            st.error(error_msg)
        return error_msg


def generate_sql_download_button(table_name: str, button_label: str = "üíæ T√©l√©charger le script SQL") -> None:
    """
    G√©n√®re et affiche un bouton de t√©l√©chargement pour le script SQL.
    
    Args:
        table_name: Nom de la table pour laquelle g√©n√©rer le script
        button_label: Texte du bouton de t√©l√©chargement
    """
    sql_script = generate_sql_from_metadata(table_name, debug_mode=False)
    
    if sql_script.startswith("‚ùå"):
        st.error(sql_script)
    else:
        st.download_button(
            label=button_label,
            data=sql_script,
            file_name=f"import_{table_name}.sql",
            mime="text/plain"
        )


def display_sql_generation_interface(table_name: str, debug_mode: bool = True) -> None:
    """
    Affiche l'interface compl√®te de g√©n√©ration SQL avec le script et les boutons.
    
    Args:
        table_name: Nom de la table pour laquelle g√©n√©rer le script
        debug_mode: Si True, affiche les informations de debug
    """
    with st.spinner("G√©n√©ration du script SQL en cours..."):
        sql_script = generate_sql_from_metadata(table_name, debug_mode=debug_mode)
        
        if sql_script.startswith("‚ùå"):
            st.error(sql_script)
        else:
            st.success("üéâ Script SQL g√©n√©r√© avec succ√®s !")
            
            # Affichage du script avec possibilit√© de copier
            st.subheader("üìÑ Script SQL d'import g√©n√©r√©")
            st.code(sql_script, language="sql")
            
            # Bouton de t√©l√©chargement
            st.download_button(
                label="üíæ T√©l√©charger le script SQL",
                data=sql_script,
                file_name=f"import_{table_name}.sql",
                mime="text/plain"
            )
            
            st.info("""
            ### üìã Instructions d'utilisation :
            1. **T√©l√©chargez** le script SQL ci-dessus
            2. **Modifiez** le chemin du fichier CSV dans la section COPY
            3. **Ex√©cutez** le script dans votre outil de gestion PostgreSQL (DBeaver, pgAdmin, etc.)
            """) 